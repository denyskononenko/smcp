{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import pickle\n",
    "#plotting \n",
    "import matplotlib.pyplot as plt \n",
    "# gaussian process\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import ConstantKernel, Matern\n",
    "# utils \n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "# dataset\n",
    "from dataset import Dataset\n",
    "# metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "RAND_ST = 26\n",
    "__notebook_path__ = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_eval(Y_test, Y_pred, Y_pred_std=None):\n",
    "    # metrics\n",
    "    rmse = mean_squared_error(Y_pred, Y_test, squared=False)\n",
    "    mae  = mean_absolute_error(Y_pred, Y_test)\n",
    "    r2   = r2_score(Y_pred, Y_test)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(6, 6)) \n",
    "\n",
    "    plt.plot(np.arange(-2, 2, 0.1), np.arange(-2, 2, 0.1), color='red')\n",
    "\n",
    "    if type(Y_pred_std) == np.ndarray:\n",
    "        plt.errorbar(Y_test.flatten(), Y_pred.flatten(), Y_pred_std.flatten(), capsize=10, marker='o', ls='none')\n",
    "    else:\n",
    "        plt.scatter(Y_test.flatten(), Y_pred.flatten())\n",
    "       \n",
    "        \n",
    "    plt.xlim([-0.05, 0.6])\n",
    "    plt.ylim([-0.05, 0.6])\n",
    "    plt.xlabel('Target')\n",
    "    plt.ylabel('Prediction')\n",
    "    plt.title(f'R2={r2:.3f}, RMSE={rmse:.3f}, MAE={mae:.3f}')\n",
    "    plt.show()\n",
    "\n",
    "def validate_model(X_train, X_test, Y_train, Y_test, nu=2.0, show_plot=True, save_plot=False):\n",
    "    \"\"\"\n",
    "    Perform validation of the GPR model.\n",
    "    \"\"\"\n",
    "    # scale data\n",
    "    scaler_X = MinMaxScaler().fit(X_train)\n",
    "    scaler_Y = MinMaxScaler().fit(Y_train)\n",
    "    X_train, X_test = scaler_X.transform(X_train), scaler_X.transform(X_test)\n",
    "    Y_train, Y_test = scaler_Y.transform(Y_train), scaler_Y.transform(Y_test)\n",
    "    \n",
    "    rfr = RandomForestRegressor(\n",
    "        warm_start=True, \n",
    "        oob_score=True, \n",
    "        n_estimators=300, \n",
    "        max_features='sqrt',\n",
    "        random_state=RAND_ST\n",
    "        )\n",
    "    # select features \n",
    "    feat_selector = SelectFromModel(rfr, threshold=0.005).fit(X_train, Y_train.flatten())\n",
    "    X_train_new = feat_selector.transform(X_train)\n",
    "    X_test_new  = feat_selector.transform(X_test)\n",
    "\n",
    "    print(f'{X_train_new.shape}')\n",
    "\n",
    "    n, p = X_train_new.shape\n",
    "\n",
    "    kernel =  ConstantKernel(1.0, (1e-36, 1e36)) + Matern(length_scale=[1] * p, length_scale_bounds=(1e-36, 1e36), nu=nu)\n",
    "    model = GaussianProcessRegressor(\n",
    "        kernel=kernel,\n",
    "        alpha=0.005, \n",
    "        n_restarts_optimizer=500,\n",
    "        random_state=RAND_ST\n",
    "        )\n",
    "\n",
    "    # fit model and evaluate on test data \n",
    "    model.fit(X_train_new, Y_train.ravel())\n",
    "    \n",
    "    Y_pred, Y_std = model.predict(X_test_new, return_std=True)\n",
    "    Y_pred_train, Y_train_std = model.predict(X_train_new, return_std=True)\n",
    "   \n",
    "    # rescale target to initial range  \n",
    "    Y_test = scaler_Y.inverse_transform(Y_test.reshape(-1, 1))\n",
    "    Y_pred = scaler_Y.inverse_transform(Y_pred.reshape(-1, 1))\n",
    "    Y_train = scaler_Y.inverse_transform(Y_train.reshape(-1, 1))\n",
    "    Y_pred_train = scaler_Y.inverse_transform(Y_pred_train.reshape(-1, 1))\n",
    "\n",
    "    if show_plot:\n",
    "        plot_model_eval(Y_test, Y_pred)\n",
    "        plot_model_eval(Y_train, Y_pred_train)\n",
    "    \n",
    "    # compute metrics \n",
    "    rmse = mean_squared_error(Y_pred, Y_test, squared=False)\n",
    "    mae  = mean_absolute_error(Y_pred, Y_test)\n",
    "    r2   = r2_score(Y_pred, Y_test)\n",
    "\n",
    "    print(f'Number of selected features: {p}: number of points: {len(X_train)} train, {len(X_test)} test')\n",
    "    print(f'rmse: {rmse} eV, mae: {mae} eV, R2: {r2}')\n",
    "\n",
    "    # export results \n",
    "    if save_plot:\n",
    "        np.savetxt(\n",
    "            f\"{__notebook_path__}/eval_results/test_std.dat\", \n",
    "            np.column_stack((Y_test.flatten(), Y_pred.flatten(), Y_std.flatten())), \n",
    "            header='Ytrue Ypred')\n",
    "\n",
    "        np.savetxt(\n",
    "            f\"{__notebook_path__}/eval_results/train_std.dat\", \n",
    "            np.column_stack((Y_train.flatten(), Y_pred_train.flatten(), Y_train_std.flatten())),\n",
    "            header='Ytrue Ypred'\n",
    "            )\n",
    "\n",
    "    return {'rmse': rmse, 'mae': mae, 'r2': r2}\n",
    "\n",
    "def save_gpr(X, Y, path):\n",
    "    \"\"\"\n",
    "    Save ML pipeline with Gaussian Process Regression for production.\n",
    "    \"\"\"\n",
    "    scaler_X = MinMaxScaler().fit(X)\n",
    "    scaler_Y = MinMaxScaler().fit(Y)\n",
    "    X = scaler_X.transform(X)\n",
    "    Y = scaler_Y.transform(Y)\n",
    "    # export scalers\n",
    "    pickle.dump(scaler_X, open(f'{path}/scalerX.sav', 'wb'))\n",
    "    pickle.dump(scaler_Y, open(f'{path}/scalerY.sav', 'wb'))\n",
    "\n",
    "    rfr = RandomForestRegressor(\n",
    "        warm_start=True, \n",
    "        oob_score=True, \n",
    "        n_estimators=300, \n",
    "        max_features='sqrt',\n",
    "        random_state=RAND_ST\n",
    "        )\n",
    "    # select features \n",
    "    feat_selector = SelectFromModel(rfr, threshold=0.005).fit(X, Y.flatten())\n",
    "    X_new = feat_selector.transform(X)\n",
    "    # export feature selector\n",
    "    pickle.dump(feat_selector, open(f'{path}/feat_selector.sav', 'wb'))\n",
    "\n",
    "    n, p = X_new.shape\n",
    "    \n",
    "    # build predictive model\n",
    "    kernel =  ConstantKernel(1.0, (1e-36, 1e36)) + Matern(length_scale=[1] * p, length_scale_bounds=(1e-36, 1e36), nu=2.0)\n",
    "    model = GaussianProcessRegressor(\n",
    "        kernel=kernel,\n",
    "        alpha=0.005, \n",
    "        n_restarts_optimizer=500,\n",
    "        random_state=RAND_ST\n",
    "        )\n",
    "\n",
    "    print(\"Fit the model\")\n",
    "    model.fit(X_new, Y.ravel())\n",
    "\n",
    "    print(\"Exporting the model\")\n",
    "    # export model \n",
    "    pickle.dump(model, open(f'{path}/model.sav', 'wb'))\n",
    "\n",
    "def load_ml(file_scalerX, file_scalerY, file_feat_selector, file_model):\n",
    "    scaler_X = pickle.load(open(file_scalerX, 'rb'))\n",
    "    scaler_Y = pickle.load(open(file_scalerY, 'rb'))\n",
    "    feat_selector = pickle.load(open(file_feat_selector, 'rb'))\n",
    "    loaded_model = pickle.load(open(file_model, 'rb'))\n",
    "    return scaler_X, scaler_Y, feat_selector, loaded_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = f'{__notebook_path__}/envs_r4_h0.005_f0.1+test'\n",
    "store_model_path = f'{__notebook_path__}/model'\n",
    "\n",
    "dataset_pd = Dataset(dataset_path).items\n",
    "# split dataset into parts with low and large hoppings\n",
    "dataset_pd_higt = dataset_pd.loc[dataset_pd['hval'] >= 0.04]\n",
    "dataset_pd_lowt = dataset_pd.loc[dataset_pd['hval'] < 0.04]\n",
    "# number of dataset items with high hopping \n",
    "n_higt = dataset_pd_higt.shape[0]\n",
    "# number of dataset items with low hopping \n",
    "n_lowt = dataset_pd_lowt.shape[0]\n",
    "# select 25 % of dataset items with low hopping\n",
    "indices_to_select_lowt = np.random.choice(np.arange(n_lowt, dtype=int), int(0.5 * n_higt)).tolist()\n",
    "dataset_pd_lowt = dataset_pd_lowt.iloc[indices_to_select_lowt]\n",
    "\n",
    "dataset_pd_concat = pd.concat([dataset_pd_lowt, dataset_pd_higt])\n",
    "\n",
    "# get numpy entities \n",
    "X = dataset_pd_concat.to_numpy()[:,3:].astype(float)\n",
    "Y = dataset_pd_concat.to_numpy()[:,1].astype(float).reshape(-1,1)\n",
    "n, p = X.shape\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=RAND_ST)\n",
    "\n",
    "print(f\"# small hopp: {dataset_pd_lowt.shape}, large hopp: {dataset_pd_higt.shape}\")\n",
    "print(X.shape)\n",
    "print(X_train.shape)\n",
    "print(np.min(Y), np.max(Y))\n",
    "print(np.min(Y_test), np.max(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_model(X_train, X_test, Y_train, Y_test, nu=2.0, save_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_gpr(X_train, Y_train, store_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d8ced83a759ba0fd829ab7b015c23ecb5f70dfb05319b17013dd345a9c600dfb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
